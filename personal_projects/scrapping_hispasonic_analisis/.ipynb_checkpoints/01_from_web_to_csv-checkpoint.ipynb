{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "825547f2",
   "metadata": {},
   "source": [
    "# Hispasonic (from web to csv)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "As a fan of electronic musical instruments, browsing through these types of pages has always been a enjoyable pastime. However, delving into data patterns is another aspect that strongly captivates me. This project perfectly merges both of my passions.\n",
    "\n",
    "Hispasonic holds significant importance in Spain as a hub for musical instruments, recording equipment, and everything within the realm of music. The platform includes a second-hand market where users can sell, purchase, exchange, or even give away their musical instruments.\n",
    "\n",
    "This initial phase of the project primarily involves gathering relevant advertisements, with a specific focus on the category of electronic musical instruments.\n",
    "\n",
    "<br>\n",
    "\n",
    "Before start obtaining information, the first thing we must know is to understand how the announcement page is organized.\n",
    "\n",
    "***\n",
    "\n",
    "- *Image of one of the pages of hispasonic*\n",
    "\n",
    "\n",
    "![hispa_1e.png](images/hispa_1e.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "We can see several important things:\n",
    "\n",
    "- Selected category is on \"teclados y sintetizadores\".\n",
    "\n",
    "- Know the number of pages that we are going to analyze to get **all the ads**.\n",
    "\n",
    "\n",
    "\n",
    "## 1. Function library loading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests               # Is an elegant and simple HTTP library for Python\n",
    "from bs4 import BeautifulSoup # library for pulling data out of HTML and XML files\n",
    "import re                     # regular expressions operations\n",
    "import pandas as pd           # A fast, powerful, flexible and easy to use open source data analysis tool\n",
    "import os                     # A versatile way to use operating system-dependent functionality.\n",
    "import datetime as dt         # module for manipulating dates and times.\n",
    "import time                   # This module provides various time-related functions.\n",
    "import random                 # This module implements pseudo-random number generators for various distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21dd00",
   "metadata": {},
   "source": [
    "### First contact\n",
    "\n",
    "First of all we must to know if we have a proper response from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72632b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html \n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8289422a",
   "metadata": {},
   "source": [
    "These are the main possible answers we can get from the server:\n",
    "\n",
    "|||\n",
    "|:--|:--|\n",
    "|**1xx informational response –** |the request was received, continuing process|\n",
    "|**2xx successful –** |the request was successfully received, understood, and accepted|\n",
    "|**3xx redirection –** |further action needs to be taken in order to complete the request|\n",
    "|**4xx client error –** |the request contains bad syntax or cannot be fulfilled|\n",
    "|**5xx server error –** |the server failed to fulfil an apparently valid request|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307a8a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the address and see the response from the server.\n",
    "\n",
    "url = \"https://www.hispasonic.com/anuncios/teclados-sintetizadores\"\n",
    "page = requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b636246b",
   "metadata": {},
   "source": [
    "#### *<Response [200]> means correct connection.*\n",
    "\n",
    "## 2. Main strategy, get the number of pages to analyze.\n",
    "\n",
    "Once we have communication, we have to know how to determine how to obtain the **total number of pages** to scrap.\n",
    "\n",
    "In each of the pages are the ads that we want to analyze, so it is very important to know how to obtain that value, since it can vary depending on the number of ads that are offered.\n",
    "\n",
    "![cantidad_iteraciones.png](images/cantidad_iteraciones.png)\n",
    "\n",
    "The item is identified as follows.\n",
    "\n",
    "       'ul', class_='pagination'\n",
    "       \n",
    "<br>\n",
    "\n",
    "**ul** means *'unordered list'* with a **class** name called `pagination`.\n",
    "\n",
    "<br>\n",
    "\n",
    "To determine the number of iterations, that is, the number of pages on which to extract the information, I must:\n",
    "\n",
    "- Find this element inside the html content.\n",
    "\n",
    "- Know the final value.\n",
    "\n",
    "<br>\n",
    "\n",
    "We will do this with [**Beautifulsoup**](https://beautiful-soup-4.readthedocs.io/en/latest/#) use to extract the contents of an element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce0da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "# soup <- all site is stored in this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2af5f5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "So inside `soup` variable we have all the site code, we are looking for `'ul', class_='pagination'`\n",
    "\n",
    "The following code refers to:\n",
    "\n",
    "- **first 5 links of the pages**\n",
    "\n",
    "- the **next 10 pages** and the **last one**, which is the one that interests us.\n",
    "\n",
    "Save it in a variable, called `unordered_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fa198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_list = soup.find('ul', class_='pagination') # into variable unordered_list\n",
    "unordered_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c423556-b070-4eb0-ba19-2ada80b963c0",
   "metadata": {},
   "source": [
    "[contents and childrens (Beautiful Soup)](https://beautiful-soup-4.readthedocs.io/en/latest/index.html?highlight=contents#contents-and-children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b9665-00ac-4166-b891-5e83811aeb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_list = unordered_list.contents # tag's children available in a list called .content. from variable to list\n",
    "unordered_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66716e9",
   "metadata": {},
   "source": [
    "### 2.1 Exploring `unordered_list` variable.\n",
    "\n",
    "`unordered_list` is a list, therefore we know what its length is and know in what position the elements that compose it are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unordered_list) # number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_list[0] # first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_list[-1] # last element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbd42c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unordered_list[-2] # this is the one I'm interested in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682ce4cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.2 How to get the value number from `unordered_list`?\n",
    "\n",
    "<br>\n",
    "\n",
    "I need to access the value within the list, so the strategy  will be the following:\n",
    "\n",
    "- 1. Convert the list to a text string.\n",
    "\n",
    "- 2. Filter the characters that correspond to numeric values, just the max ones.\n",
    "\n",
    "- 3. Convert those numeric characters to numbers (int).\n",
    "\n",
    "<br>\n",
    "\n",
    "I will convert the contents of the list into a text string and have the numeric characters extracted together with highest values by using regular expressions.\n",
    "\n",
    "**1. Converting the content of `paginas` into a text string**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = str(unordered_list[-2])\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da0c8e8",
   "metadata": {},
   "source": [
    "**2/3. Filter the characters that correspond to numeric values, just the max ones** and **Convert those numeric characters to numbers (int)**.\n",
    "\n",
    "`extractMax` A function that gets the numbers contained in the lowercase text and converts them to integer numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56138a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMax(input):\n",
    "     # get a list of all numbers separated by \n",
    "     # lower case characters \n",
    "     # \\d+ is a regular expression which means\n",
    "     # one or more digit\n",
    "     # output will be like ['100','564','365']\n",
    "    numbers = re.findall(r'\\d+',input)\n",
    "     # now we need to convert each number into integer\n",
    "     # int(string) converts string into integer\n",
    "     # we will map int() function onto all elements \n",
    "     # of numbers list\n",
    "    numbers = map(int,numbers)\n",
    "    return max(numbers) # returns a int number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bec164",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_numbers = extractMax(test)\n",
    "page_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e1f3e",
   "metadata": {},
   "source": [
    "We already have the number of pages that we will have to analyze. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8367e4",
   "metadata": {},
   "source": [
    "## 3. Getting and save all links (ads and not ads)\n",
    "\n",
    "Once we have the number of pages in which we must extract the ads, the next step is to extract those ads from each of the pages looking inside the code of each of them.\n",
    "\n",
    "So what we have to do is:\n",
    "\n",
    "- Extracting **everything that is a link**.\n",
    "\n",
    "\n",
    "- From the links extracted, the most important thing is get the final number which is the way to **identify those who are ads and what are not**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_ads = []        # all the ads on the page\n",
    "listado_enlaces = []  # all the links on the page\n",
    "\n",
    "pattern=\"([0-9]{4,9})\" # filtering all links with number, that mean choosing the page number related to and ad.\n",
    "\n",
    "for pagina in range(page_numbers, 0, -1): \n",
    "    url = \"https://www.hispasonic.com/anuncios/teclados-sintetizadores/pagina{pagina}\".format(pagina=pagina)\n",
    "    print(url)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    \n",
    "    for link in soup.find_all('a'):       # filter everything that is a link on soup variable\n",
    "        links_ads.append(link.get('href'))\n",
    "        fecha = soup.find_all('span', class_='miniicon miniicon-date')\n",
    "        \n",
    "    \n",
    "    for link_ad in links_ads:                   # of those links what I do is stay with what ends in number\n",
    "        if re.search(pattern, link_ad):\n",
    "            listado_enlaces.append(link_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ad853",
   "metadata": {},
   "source": [
    "#### This is a small sample of the contents of the lists\n",
    "\n",
    "It can be seen as being links in both cases, in the first we only have **links that do not interest us**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e69fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_ads[5:20] # example: row 5 to 20 of everything is a link on soup variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7d2c1e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "However in the second list `listado_enlaces` what we have are the **links we want to get in each of the pages**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe14e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_enlaces[5:20] # example: of those links what I do is stay with what ends in number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc69f5",
   "metadata": {},
   "source": [
    "## 3.1 Cleaning links.\n",
    "\n",
    "Taking a look into `listado_enlaces` it is striking that there are links that are repeated.\n",
    "\n",
    "            '...\n",
    "            '/anuncios/korg-vocoder-vc10/866556',\n",
    "             '/anuncios/korg-vocoder-vc10/866556',\n",
    "             '/anuncios/polyend-tracker/1057403',\n",
    "             '/anuncios/polyend-tracker/1057403',\n",
    "             '/anuncios/trajetas-teclados/949462',\n",
    "             '/anuncios/trajetas-teclados/949462',\n",
    "                                             ...',\n",
    "\n",
    "<br>\n",
    "\n",
    "### We need to do a couple of things.\n",
    "\n",
    "- 1. **Extract** the brand name from the url using regular expressions.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "![regex_expression.png](images/regex_expression.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "- 2. **Filter** the amount of url repeated.\n",
    "\n",
    "<br>\n",
    "\n",
    "To get **not repeated url**, we will make a **filter with a dictionary**.\n",
    "\n",
    "The main idea is filter the url repeated as `key` and asign it a synth brand for this unique url as `value`.\n",
    "\n",
    "\n",
    "### Carga de los htmls en modo local:\n",
    "\n",
    "Activo esta ruta con los htmls dentro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89569408-3f0b-4e9c-862f-bf6067d2efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ion/Documentos/albertjimrod/hispaok/htmls') # folder where htmls folder is ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f337e-c983-4f1c-b2b7-363ed2df7ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "ruta = '/home/ion/Documentos/albertjimrod/hispaok/htmls'\n",
    "listado_enlaces = [f for f in listdir(ruta) if isfile(join(ruta, f))] # Esto simplemente comprueba los htmls\n",
    "listado_enlaces[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae73d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_enlaces = {} # dict\n",
    "\n",
    "listado_marcas = []      # synth_brand\n",
    "\n",
    "patron_marca = r\"((?<=anuncios\\/)[1-9][a-z]{1,})|((?<=anuncios\\/)[a-z]{1,})\" # filter brand regex\n",
    "\n",
    "for enlace in listado_enlaces:\n",
    "    if enlace not in diccionario_enlaces:  \n",
    "        try:\n",
    "            marca = re.search(patron_marca, enlace).group()\n",
    "            diccionario_enlaces[enlace] = marca\n",
    "        except AttributeError:\n",
    "            #marca = re.search(patron_marca, enlace)\n",
    "            pass # voy a ver si funciona, lo que aprendi del try except"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8024069",
   "metadata": {},
   "source": [
    "With the dictionary that we have just created we are going to download all the ads locally.\n",
    "\n",
    "The reason is not to overload the server and run the risk of being banned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e9f22",
   "metadata": {},
   "source": [
    "## 3.2 Download all the ads.\n",
    "\n",
    "\n",
    "To avoid the inconvenience that would suppose the overload of the server, we will download all the ads in local mode adding a delay in the download time. In this way we will work with more comfort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a85560",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "main_path='https://www.hispasonic.com'\n",
    "local_path = '/home/ion/Documentos/albertjimrod/hispaok/htmls/'\n",
    "\n",
    "for enlace in diccionario_enlaces:\n",
    "    time.sleep(random.uniform(2, 5))                           # intervalo en el que muestreo\n",
    "    page = requests.get(main_path + enlace) # https://www.hispasonic.com/anuncios/polyend-tracker/1057403.html\n",
    "    #print(main_path + enlace)\n",
    "    enlace = enlace.split(\"/\")              # filter for extracting\n",
    "    enlace= enlace[2]                       # name ad\n",
    "\n",
    "    print(local_path + enlace)\n",
    "\n",
    "    with open(local_path + enlace + '.html',\"w+\") as f:\n",
    "        f.write(page.text)\n",
    "        \n",
    "    print(local_path + enlace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bb6c3f",
   "metadata": {},
   "source": [
    "## 3.3 It's not all about sales.\n",
    "\n",
    "<br>\n",
    "\n",
    "When ads have been downloaded, the next step is doing a quick scan inside the downloaded ads, so there's no only sales.\n",
    "\n",
    "\n",
    "A starting point is to look in the description of the titles and see if some of these words exist.\n",
    "\n",
    "\n",
    "By using `find` and `grep` together we can see if these words we are looking for are inside the files.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "![vendo.png](images/vendo.png)\n",
    "\n",
    "- **vendo : *sell***\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "![busco_piezas.png](images/busco_piezas.png)\n",
    "\n",
    "- **busco, se busca: *looking for*** and - **piezas: *parts***\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "![cambio.png](images/cambio.png)\n",
    "\n",
    "- **cambio: *change***\n",
    "\n",
    "<br>\n",
    "    \n",
    "![compro.png](images/compro.png)\n",
    "\n",
    "- **compro: *buy***\n",
    "\n",
    "<br>\n",
    "\n",
    "![regalo.png](images/regalo.png)\n",
    "\n",
    "- **regalo: *for free***\n",
    "\n",
    "<br>\n",
    "\n",
    "This information will be very useful because these are the actions, and it will allow us to classify if the ad is for sale, purchase or any other concept that we have discovered.\n",
    "\n",
    "## 3.4 Elements of the ad that we are going to extract.\n",
    "\n",
    "<br>\n",
    "Another step to take into account is to obtain:\n",
    "\n",
    "- **description**, **user**, **price**, **brand**, **city** , **date published** ,**date expire** ,**times seen**\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "![hispa_4.png](images/hispa_4.png)\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "This is an ad as example and the fields we want to get:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123e433",
   "metadata": {},
   "source": [
    "## 3.5 Extraction of the \"action\" and the synthesizer name from the description.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3.5-1 Extraction of action\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "The extraction contained in the fields is not very complicated, however in the description we find a problem to solve and it is about how to differentiate a sale, a purchase or a change.\n",
    "\n",
    "\n",
    "To do this, the solution carried out has been to use a series of keywords in the meaning of the ad as triggers of an **accion: *action*** in the event that those words exist in the description of the advertisement. \n",
    "\n",
    "\n",
    "In the same way as we (humans) would do to see if the ad is a sale or on the contrary a gift.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e52429",
   "metadata": {},
   "outputs": [],
   "source": [
    "accion = [\"compro\",\"cambio\",\"vendo\",\"regalo\",\"busco\",\"busca\",'reparar','piezas']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5bb2d3",
   "metadata": {},
   "source": [
    "Once we have the `accion` keywords list, the next step is to make them as a trigger, that is, manage to make a certain action.\n",
    "\n",
    "<br>\n",
    "\n",
    "Using the words contained in `accion` list as the key, and the value of the dictionary a call to a function depending the action on acción.\n",
    "\n",
    "<br>\n",
    "\n",
    "    func_dict = {                      # the key give us the action (function)\n",
    "        \"compro\":func_compro,\n",
    "        \"cambio\":func_cambio,\n",
    "        ...\n",
    "\n",
    "\n",
    "    def func_compro(clave_func_dict):  # if `compro` means I am not selling, and so on...\n",
    "\n",
    "    if list_compro[-1] == \"0\":  \n",
    "        list_vendo.pop(-1)\n",
    "        list_vendo.append(\"0\")\n",
    "        list_compro.pop(-1)\n",
    "        list_compro.append(\"1\")\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3.5-1 Extraction of synthesizer name.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "The next step we must implement is all the possible brands of synthesizer manufacturers that we can find in the ads. \n",
    "\n",
    "\n",
    "To do this by doing an internet search I could find a list of a large number of them, at least to date.\n",
    "\n",
    "\n",
    "However due to the time I have been working with the project I already have a list of names `sintes` with which I have been working but that when I reached this point I realized that I had to modify and merge with the new list.\n",
    "\n",
    "link where I obtain the brand synth: https://www.perfectcircuit.com/modular-synths\n",
    "\n",
    "#### Synthesizer manufacturers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03145eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sintes = ['0 coast', '0-coast', '000', '4ms', 'a-v-p synth', 'acces', 'access', 'acidlab', 'akai', 'alembic', 'alesis', 'allen & heath', 'allen&heath', \n",
    "'analogaudio1', 'analogue solutions', 'analogue systems', 'arp', 'arturia', 'asm', 'asm (ashun sound machines)', 'atomo synth', 'atomosynth', 'audio damage', \n",
    "'audiophile circuits league', 'axoloty', 'balaguer', 'baloran', 'bastl instruments', 'befaco', 'behringer', 'behringer', 'bheringer', 'bitbox', \n",
    "'black corporation', 'boss', 'bubblesound instruments', 'buchla', 'bÃ¶hm', 'casio', 'charlie lab', 'charvel', 'chronograf', 'circuit abbey', 'clavia', \n",
    "'club of the knobs', 'coast', 'corsynth', 'cre8audio', 'crumar', 'custom made synths', 'cyclone', 'cyclone analogic', 'dave jones design', 'dave smith', \n",
    "'dave smith instruments', 'deepmind', 'deepmind 12', 'deepmind 6', 'delptronics', 'delta music', 'denon dj', 'dexibell', 'dexibell', 'digitack', 'doepfer', \n",
    "'dreadbox', 'dubreq', 'dynacord', 'e mu', 'e-mu', 'e-mu', 'e:m:c', 'elby designs', 'electribe', 'electronic music laboratories (eml)', \n",
    "'electrovoice', 'elektron', 'elka', 'emc', 'emu', 'endorphin.es', 'endorphines', 'ensoniq', 'eowave', 'epiphone', 'erica synth', 'erica synths', \n",
    "'ernie ball music man', 'esp ltd', 'eurorack', 'eventide', 'evh', 'evolver', 'exodus digital', 'farfisa', 'fender', 'fishman', 'fodera', 'formanta', \n",
    "'frap tool', 'frequency central', 'fretlight', 'friedman', 'future retro', 'futuresonus', 'gator', 'gemini', 'generalmusic', 'gibson', 'godin', 'gotharman', \n",
    "'graph tech', 'gretsch', 'guild', 'hammond', 'hartmann', 'hexinverter', 'hinton instruments', 'hofner', 'hypersynth', 'hÃ¶fner', 'ibanez', 'ik', 'instruo', \n",
    "'intellijel', 'iomega', 'isla', 'jackson', 'jaspers', 'john bowen synth design', 'jomox', 'kawai', 'kenton', 'ketron', 'kilpatrick audio', 'knobula', \n",
    "'koma elektronik', 'komplete', 'korg', 'kramer', 'kurzweil', 'kurzweil', 'lakland', 'line 6', 'linn electronics', 'livid', 'logan electronics', 'm-audio', \n",
    "'macbeth studio systems', 'make', 'malekko', 'manikin electronic', 'maschine', 'mellotron', 'mfb', 'micro modular', 'miditech', 'modal', 'modal electronics', \n",
    "'models', 'modor', 'modular', 'modulus', 'monome', 'moog', 'mpc', 'mpc', 'mutable instruments', 'mutant', 'native instruments', 'neutron', 'noise engineering', \n",
    "'nord', 'nord electro', 'nord lead 2 rack', 'nord lead 3', 'nord lead 3', 'nord lead 4', 'nord micro modular', 'nord modular', 'nord rack', 'nord stage', \n",
    "'nord wave', 'novation', 'numark', 'oberheim', 'octatrack', 'orthogonal devices', 'paratek', 'pearl', 'peavey', 'pioneer dj', 'pittsburgh', 'pittsburgh modular', \n",
    "'polyend', 'polygraf', 'ppg (palm products gmbh)', 'prs', 'qu bit', 'qu-bit', 'qu-bit electronix', 'quasimidi', 'qubit', 'quiklok', 'radikal technologies', \n",
    "'rhodes', 'rickenbacker', 'roland', 'roli', 'sanson', 'schecter', 'sensel', 'sequencial', 'sequential', 'sequential', 'sequential circuits', \n",
    "'sequential circuits', 'sequentix', 'shakmat', 'simmons', 'soma', 'sonicware', 'special waves', 'spector', 'spectral audio', 'sputnik', 'squarp instruments', \n",
    "'squier', 'ssff', 'stanton', 'steinberger', 'sterling', 'strymon', 'studio electronics', 'studiologic', 'studiologic music', 'synamodec', 'synthesis technology', \n",
    "'synthrotek', 'synthstrom', 'synthstrom', 'synthtech','swissonic', 'tascam', 'taylor', 'technos', 'teenage', 'teenage engineering', 'tiptop', 'tiptop audio', \n",
    "'traveler guitar', 'udo audio', 'uno synth ', 'vermona', 'vermona', 'virus', 'viscount', 'volca', 'vox', 'waldorf', 'warwick', 'washburn', 'waves grendel', \n",
    "'wersi', 'wersi music', 'winter modular', 'wmd', 'wmd / ssf', 'wurlitzer', 'yamaha', 'yocto', 'zeppelin design labs', 'zoom','1010 music', '2hp', '4ms', 'acid rain technology', \n",
    "'acl', 'addac system', 'after later audio', 'aion modular', 'ajh synth', \n",
    "'alm busy circuits', 'alright devices', 'analogue solutions', 'bastl instruments', 'befaco', 'blackhole cases', 'blue lantern', 'boredbrain music', \n",
    "'bubblesound', 'buchla', 'cosmotronic', 'cre8audio', 'divkid', 'dnipro modular', 'doepfer', 'dreadbox', 'e-rm', 'electrosmith', 'emblematic systems', \n",
    "'empress effects', 'endorphin.es', 'eowave', 'erica synths', 'erogenous tones', 'eskatonic modular', 'eventide', 'five12', 'frap tools', 'future sound systems', \n",
    "'gieskes', 'grayscale', 'hexinverter', 'industrial music electronics', 'instruo', 'intellijel designs', 'io instruments', 'jomox', 'joranalogue', 'klavis', \n",
    "'koma elektronik', 'l-1', 'lmntl', 'low-gain electronics', 'lzx industries', 'make noise', 'malekko heavy industry', 'manhattan analog', 'meng qi', \n",
    "'michigan synth works', 'modbap modular', 'moog', 'mordax', 'mosaic', 'mrseri', 'mutable instruments', 'nano modules', 'noise engineering', \n",
    "'patching panda', 'percussa', 'pittsburgh modular', 'plankton electronics', 'poly effects', 'qu-bit electronix', 'random source', 'ritual electronics', \n",
    "'rossum', 'schlappi engineering', 'shakmat modular', 'soundforce', 'soundmachines', 'squarp', 'steady state fate', 'strymon', 'studio electronics', \n",
    "'supercritical', 'synthesis technology', 'system 80', 'tall dog electronics', 'tasty chips', 'tenderfoot electronics', 'tesseract modular', 'tiptop audio', \n",
    "'trogotronic', 'tubbutec', 'u-he', 'verbos electronics', 'vermona', 'voicas', 'vpme.de', 'winter modular', 'wmd', 'worng electronics', 'xaoc devices', \n",
    "'xor electronics', 'zlob modular',\"ASM\",\"Elektron\",\"Moog\",\"Sequential\",\"Teenage Engineering\",\"SOMA Laboratory\",\"Korg\",\"Novation\",\"Modal Electronics\",\n",
    "\"Black Corporation\",\"Roland\",\"Arturia\",\"Critter & Guitari\",\"Polyend\",\"UDO\",\"Waldorf\",\"Nord\",\"Yamaha\",\"Vermona\",\"Crumar\",\"JMT Synth\",\"Modor\",\n",
    "\"Studio Electronics\",\"Trogotronic\",\"Gieskes\",\"Akai\",\"Dreadbox\",\"Herbs and Stones\",\"IK Multimedia\",\"Tasty Chips\",\"Buchla\",\"Soundmachines\",\n",
    "\"Access\",\"Grp\",\"Analogue Solutions\",\"The Division Department\",\"Norand\",\"Jomox\",\"Sonicware\",\"Radikal Technologies\",\"Playtime Engineering\",\n",
    "\"1010 Music\",\"Fred's Lab\",\"Kilpatrick Audio\",\"Eowave\",\"Electrosmith\",\"Meng Qi\",\"Studiologic\",\"Suzuki\",\"Nonlinear Labs\",\"Dato\",\"Artiphon\",\n",
    "\"Malekko Heavy Industry\",\"Kodamo\",\"Hikari Instruments\",\"Manikin Electronic\",\"Second Sound\",\"\",\"Arturia\",\"Squarp\",\"Polyend\",\"Novation\",\"Akai\",\n",
    "\"Roger Linn Design\",\"Conductive Labs\",\"Native Instruments\",\"Faderfox\",\"Sensel\",\"Roland\",\"Keith McMillen\",\"Pioneer\",\"E-RM\",\"Expressive E\",\"Korg\",\n",
    "\"M-Audio\",\"Alesis\",\"JouÃ©\",\"Soundforce\",\"Yamaha\",\"Genki\",\"Erica Synths\",\"SOMA Laboratory\",\"Make Noise\",\"Doepfer\",\"Elektron\",\"Moog\",\n",
    "\"Teenage Engineering\",\"1010 Music\",\"Expert Sleepers\",\"BASTL Instruments\",\"Kenton\",\"Circuit Happy\",\"MOTU\",\"MIDI Solutions\",\"Solid State Logic\",\n",
    "\"Nord\",\"Malekko Heavy Industry\",\"Koma Elektronik\",\"Random Source\",\"Eowave\",\"Zoom\",\"Crumar\",\"Electro-Harmonix\",\"Grp\",\"Michigan Synth Works\",\n",
    "\"Analogue Solutions\",\"Knas\",\"iConnectivity\",\"Soundmachines\",\"Eurodesk-Z\",\"Presonus\",\"Torso Electronics\",\"IK Multimedia\",\"ESI Audiotechnik\",\n",
    "\"Low-Gain Electronics\",\"Kilpatrick Audio\",\"Artiphon\",\"Instruments of Things\",\"Apogee\",\"SND\",\"Future Retro\",\"Moffenzeef\",\"CME\",\"Embodme\",\n",
    "\"Tech 21\",\"Snyderphonics\",\"Tricks Magic Shop\",\"\",\"\",\"Strymon\",\"Vermona\",\"OTO Machines\",\"Dreadbox\",\"Chase Bliss Audio\",\"Boss\",\"GFI\",\"Meris\",\n",
    "\"Eventide\",\"SOMA Laboratory\",\"Echo Fix\",\"Fairfield Circuitry\",\"Universal Audio\",\"Gamechanger Audio\",\"EarthQuaker Devices\",\"Death By Audio\",\n",
    "\"Sherman\",\"Electro-Harmonix\",\"Old Blood Noise Endeavors\",\"Knas\",\"Red Panda\",\"Malekko Heavy Industry\",\"Kemper\",\"DigiTech\",\"JAM Pedals\",\n",
    "\"Erica Synths\",\"Elektron\",\"WMD\",\"1010 Music\",\"Roland\",\"Korg\",\"Poly Effects\",\"Jomox\",\"Thermionic Culture\",\"Decksaver\",\"Warm Audio\",\n",
    "\"Zoom\",\"Boredbrain Music\",\"Meng Qi\",\"Electrosmith\",\"Benidub\",\"BAE\",\"Trogotronic\",\"MIDI Solutions\",\"Plankton Electronics\",\"Vongon\",\n",
    "\"ART\",\"Hungry Robot\",\"Walrus Audio\",\"Enjoy Electronics\",\"CIOKS\",\"TK Audio\",\"Source Audio\",\"API\",\"Kilpatrick Audio\",\"Voodoo Lab\",\n",
    "\"FMR Audio\",\"JHS Pedals\",\"MOD Devices\",\"Cooper FX\",\"Finegear\",\"Ezhi & Aka\",\"Truetone\",\"LastGasp Art Laboratories\",\"Origin Effects\",\n",
    "\"Rainger FX\",\"Line 6\",\"PedalTrain\",\"Dr. Scientist\",\"Elta Music\",\"Keeley\",\"Recovery\",\"Glou-Glou\",\"Retro Mechanical Labs\",\"Electro-Faustus\",\n",
    "\"Animal Factory\",\"Hologram\",\"Caroline Guitar Company\",\"MXR\",\"Second Sound\",\"Xotic\",\"Dunlop\",\"Adventure Audio\",\"ISP Technologies\",\n",
    "\"Industrialectric\",\"Tech 21\",\"Collision Devices\",\"Orgeldream\",\"Universal Audio\",\"API\",\"Solid State Logic\",\"Rupert Neve Designs\",\"Shure\",\"MOTU\",\n",
    "\"Warm Audio\",\"Focusrite\",\"Vermona\",\"Focal\",\"Neumann\",\"Roland\",\"Thermionic Culture\",\"Arturia\",\"Zoom\",\"Presonus\",\"Adam\",\"ART\",\"Yamaha\",\n",
    "\"TASCAM\",\"Furman\",\"Antelope Audio\",\"Dangerous Music\",\"Pioneer\",\"Echo Fix\",\"Native Instruments\",\"Decksaver\",\"Eventide\",\"Allen & Heath\",\n",
    "\"Meris\",\"Sherman\",\"dbx\",\"BAE\",\"Maag Audio\",\"Empirical Labs\",\"Avantone Pro\",\"iConnectivity\",\"Mackie\",\"Audient\",\"beyerdynamic\",\"TK Audio\",\n",
    "\"IK Multimedia\",\"Black Lion Audio\",\"RME\",\"Keith McMillen\",\"Golden Age Project\",\"Audio-Technica\",\"Fredenstein\",\"A-Designs\",\"Rosson Audio\",\n",
    "\"Daking\",\"Looptrotter\",\"Rode\",\"Prism Sound\",\"Samson\",\"Cranborne Audio\",\"ESI Audiotechnik\",\"Elysia\",\"HEDD\",\"FMR Audio\",\"Heritage Audio\",\n",
    "\"Avedis Audio\",\"Sennheiser\",\"Lindell Audio\",\"Blue Microphones\",\"Apogee\",\"Recovery\",\"M-Audio\",\"Zeppelin Design Labs\",\"KRK\",\"AKG\",\n",
    "\"Cloud Microphones\",\"Steinberg\",\"Alesis\",\"Dynaudio\",\"Austrian Audio\",\"Auralex\",\"IsoAcoustics\",\"Aston Microphones\",\"Auratone\",\"sE Electronics\",\"SE Electronics\",\n",
    "\"Tech 21\",\"Lauten Audio\",\"Cascade Microphones\",\"Soundrise\",\"Pioneer\",\"Allen & Heath\",\"Pro-Ject\",\"PLAYdifferently\",\"U-Turn Audio\",\"Audio-Technica\",\n",
    "\"Thorens\",\"Audioengine\",\"Technics\",\"Rane\",\"AKG\",\"Music Hall\",\"Native Instruments\",\"Numark\",\"Sennheiser\",\"Jesse Dean Designs\",\"Ortofon\",\"Decksaver\",\n",
    "\"Rosson Audio\",\"MWM\",\"Gator\",\"IK Multimedia\",\"ART\",\"Yamaha\",\"Ultimate Support\",\"RME\",\"Roland\",\"KRK\",\"Austrian Audio\",\"Shure\",\"Odyssey\",\n",
    "\"Teenage Engineering\",\"Denon\",\"Record Props\",\"Presonus\",\"Hosa\",\"Hosa\",\"Mogami \",\"Roland \",\"Voodoo Lab \",\"CIOKS \",\"LMNTL \",\"Warm Audio \"\n",
    "\"Teenage Engineering \",\"myVolts \",\"Gator \",\"Truetone \",\"Strymon \",\"Eurodesk-Z\",\"Furman\",\"Elektron\",\"Tiptop Audio\",\"Retrokits\",\"4MS\",\"EBS\",\n",
    "\"Pomona Electronics\",\"Modbang\",\"Intellijel Designs\",\"Plankton Electronics\",\"Radial Engineering\",\"1010 Music\",\"Native Instruments\",\n",
    "\"Expert Sleepers\",\"Buchla\",\"iConnectivity\",\"Modbap Modular\",\"Boredbrain Music\",\"Make Noise\",\"Korg\",\"Moog \",\"Rode \",\"Shure \",\n",
    "\"LabLab Audio \",\"Zoom \",\"Doepfer \",\"Koma Elektronik \",\"ADDAC System \",\"Frap Tools \",\"Endorphin.es \",\"ART s\",\"Yamaha \",\"Walrus Audio\",\n",
    "\"ALM Busy Circuits \",\"Analogue Solutions \",\"Trogotronic \",\"Befaco \",\"Boss \",\"Soundmachines \",\"LZX Industries \",\"Cyclone Analogic \",\n",
    "\"M-Audio \",\"E-RM \",\"Pulp Logic \",\"Electro-Harmonix \",\"ESI Audiotechnik \",\"Eskatonic Modular \",\"Eventide \",\"Instruo \",\"Keith McMillen\",\n",
    "\"Malekko Heavy Industry \",\"Dunlop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing whole names in list.\n",
    "\n",
    "lista_criba = []\n",
    "\n",
    "for marca in sintes:\n",
    "    marca = marca.lower()\n",
    "    if marca not in lista_criba:\n",
    "        lista_criba.append(marca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae7396",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_criba[2:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b4422a",
   "metadata": {},
   "source": [
    "- Once I clean the list of possible repeated names, what I do next is that the names composed of two terms are a list of two elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddbef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split double names in list\n",
    "\n",
    "lista_sintes= []\n",
    "\n",
    "for marca in lista_criba:\n",
    "    marca = marca.lower()\n",
    "    if marca not in lista_sintes:\n",
    "        marca=marca.split()\n",
    "        lista_sintes.append(marca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdeb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_sintes[2:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125dbd04",
   "metadata": {},
   "source": [
    "## 3.6 How to identify manufacturer brands?.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "There are many names with two or three terms and some of them are unique, but others have the first name in common.\n",
    "\n",
    "for example:\n",
    "\n",
    "<br>\n",
    "\n",
    "    ...analogue systems, analogue solutions...\n",
    "    \n",
    "<br>\n",
    "\n",
    "To solve this problem we have to do:\n",
    "\n",
    "\n",
    "- Building a manufacturers' dictionary.\n",
    "\n",
    "- Implement an algorithm that differentiates between multiple manufacturer brands\n",
    "\n",
    "\n",
    "As an example we will use this small dictionary as if it were our dictionary of synthesizer manufacturers:\n",
    "\n",
    "  - Manufacturers' dictionary:\n",
    "\n",
    "\n",
    "    sint3 = {\"analogue\":[\"solutions\",\"systems\"]} \n",
    "    \n",
    " \n",
    "\n",
    "The implementation of the algorithm will be based on detecting:\n",
    "\n",
    "- *single names*: `Roland`\n",
    "\n",
    "- *double and unique names*:  `Dave Smith`\n",
    "\n",
    "- *double names with a first name common to different manufacturers*: `Analogue Systems or Analogue Solutions`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "The particularity of **this** example is that it allows us to see one of the most controversial cases when it comes to the extraction of a name. \n",
    "\n",
    "### example of algorithm implementation:\n",
    "\n",
    "With this example what is intended is just to detect the correct name in the variable of the description, ie:\n",
    "\n",
    "- `Analogue Systems`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c57491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to detect manufacturer brands with same name and different 'surname'\n",
    "\n",
    "\n",
    "texto_descript = ''\n",
    "\n",
    "# Our manufaturer brand in a dictionary!\n",
    "sint3 = {\"analogue\":[\"solutions\",\"systems\"]}  \n",
    "\n",
    "# Example description ad\n",
    "descrip = ['analogue', 'systems', 'woggeblug', '+', 'morphagene', '+', 'optomix'] \n",
    "\n",
    "texto_marca_compuesta =''\n",
    "kompare = ''\n",
    "\n",
    "list_temp = []\n",
    "list_brand = []                                     # steps\n",
    "\n",
    "for idx in descrip:                                 # 1. #7. \n",
    "    if idx in kompare:                              # 2. #8.\n",
    "                                                    \n",
    "        list_temp.append(idx)                            # 9. \n",
    "        for palabritas in list_temp:                 \n",
    "            texto_descript += ' '+ palabritas            # 10.\n",
    "\n",
    "        #list_brand.append(texto_descript)               # 11.\n",
    "        kompare = ''                                     # 12.\n",
    "        list_temp.clear()                                # 13.\n",
    "\n",
    "        \n",
    "\n",
    "    elif idx in sint3:                              # 3.\n",
    "        if len(sint3[idx]) > 1:                     # 4.\n",
    "            list_temp.append(idx)                   # 5.\n",
    "            print(sint3[idx])\n",
    "            kompare = sint3[idx]                    # 6.\n",
    "\n",
    "        \n",
    "print(texto_descript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb0e5c",
   "metadata": {},
   "source": [
    "- We have the correct name: `analogue systems` thru the dictionary where they share a \"name\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b245de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. for starts                   # 7. the idx already has the second name of the synth.\n",
    "\n",
    "# 2. if idx coincides with the content of a kompare, else go to next elif.\n",
    "\n",
    "                                # 8. if comparing the idx with the variable that contains the match if true\n",
    "                                # 9. Saving the second match in the temporary list\n",
    "                                # 10. I convert the items in the list to a text string\n",
    "\n",
    "\n",
    "                                # 11  Assign the string into the brand list\n",
    "                                # 12. clean the value of the kompare variable and texto_marca_compuesta\n",
    "                                # 13. clean the contents of the temporary list\n",
    "\n",
    "        \n",
    "\n",
    "# 3. if the index is contained in the sint3 dictionary \n",
    "# 4. and the length of the dictionary key value is greater than 1 means we have at least two possible marks.\n",
    "# 5. I store this first match in a temporary list\n",
    "\n",
    "# 6. And save the list of possible matches in a variable, which was initially void with ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba6816",
   "metadata": {},
   "source": [
    "in the previous example we made use of a small dictionary that we could make by hand, but we need to implement a dictionary with all manufacturers.\n",
    "\n",
    "\n",
    "## Building the manufacturer's dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22abe3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "marcas_nombres = []\n",
    "\n",
    "def sint_word(sintex):\n",
    "    marcas_nombres.append(sintex)\n",
    "    return [marcas_nombres[-1]]\n",
    "\n",
    "def sint_more_word_rep(sintex):\n",
    "    # no es necesario que devueva una lista ya que dentro del diccionario ya la tengo!\n",
    "    marcas_nombres.append(sintex)\n",
    "    return marcas_nombres[-1]\n",
    "\n",
    "\n",
    "dict_funct = {\"sint_word\":sint_word,\n",
    "            \"sint_more_word_rep\":sint_more_word_rep\n",
    "}\n",
    "\n",
    "dict_marca = {}\n",
    "\n",
    "tag_mark = ''\n",
    "for marcas in lista_sintes:\n",
    "    if len(marcas) == 1:\n",
    "        if marcas[0] not in dict_marca:\n",
    "            tag_mark = 'sint_word'\n",
    "            brand = marcas[0]\n",
    "            ret = dict_funct[tag_mark](brand)\n",
    "            \n",
    "            dict_marca[brand] = ret\n",
    "            #print(\"x\")\n",
    "    elif len(marcas) > 1:                           # aqui la marca tiene este formato: ['0', 'coast']\n",
    "        if marcas[0] not in dict_marca:\n",
    "            tag_mark = 'sint_word'\n",
    "            #print(marcas[0])\n",
    "            #print(marcas[1])\n",
    "\n",
    "           \n",
    "            ret = dict_funct[tag_mark](marcas[1])\n",
    "            dict_marca[marcas[0]] = ret\n",
    "\n",
    "        elif marcas[0] in dict_marca:\n",
    "            tag_mark = 'sint_more_word_rep'\n",
    "            ret = dict_funct[tag_mark](marcas[1])\n",
    "            dict_marca[marcas[0]].append(ret)\n",
    "            #print(\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e256db68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dict_marca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca6b6e",
   "metadata": {},
   "source": [
    "It will give us:\n",
    "\n",
    "<br>\n",
    "\n",
    "- What was inside of `sint3[idx]` ['solutions', 'systems'] thanks to a print.\n",
    "\n",
    "\n",
    "- Finally we have the we have the right name of the description, as we expected.\n",
    "\n",
    "<br>\n",
    "\n",
    "Once we understand the operation we are going to implement the necessary code.\n",
    "\n",
    "\n",
    "## 3.7 Detecting manufacturer brands.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38bd4c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare = ''                    #variable where the middle name is saved\n",
    "marca_del_sinte = ''            # empty variable for store synth brand \n",
    "texto_descriptivo = ''          #ad descriptive text\n",
    "list_temp = []                  #temporary list to detect the middle name \n",
    "\n",
    "                                # buy, sell, change... lists.\n",
    "list_compro = []\n",
    "list_cambio = []\n",
    "list_vendo = []\n",
    "list_regalo = []\n",
    "list_busco = []\n",
    "list_rebaja = []\n",
    "list_reparar = []\n",
    "list_piezas = []\n",
    "list_urgente = []\n",
    "list_oferta = []\n",
    "\n",
    "list_brand = []                 # manufacturers synth brand\n",
    "list_descripcion = []           # final ad description on dataframe output \n",
    "texto_descriptivo_salida = []   # esto es el contenido del anuncio\n",
    "\n",
    "list_price = []                 # price\n",
    "list_user = []                  # user\n",
    "list_city = []                  # city\n",
    "list_published = []             # date published\n",
    "list_expire = []                # data expire ad\n",
    "list_times_seen= []             # times seen ad\n",
    "\n",
    "list_original=[]\n",
    "\n",
    "lista_palabras_para_eliminar = [] # en esta lista voy a ir añadiendo las palabras que debo ir eliminado del anuncio. Acciones, marca del sinte, \n",
    "\n",
    "def func_compro(clave_func_dict): \n",
    "    if list_compro[-1] == \"0\":\n",
    "        list_vendo.pop(-1)\n",
    "        list_vendo.append(\"0\")\n",
    "        list_compro.pop(-1)\n",
    "        list_compro.append(\"1\")\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "def func_cambio(clave_func_dict):\n",
    "    if list_cambio[-1] == \"0\":\n",
    "        list_vendo.pop(-1)\n",
    "        list_vendo.append(\"0\")\n",
    "        list_cambio.pop(-1)\n",
    "        list_cambio.append(\"1\")\n",
    "        #list_price.append(\"0\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def func_vendo(clave_func_dict):\n",
    "    if list_vendo[-1] == \"0\":\n",
    "        list_vendo.pop(-1)\n",
    "        list_vendo.append(\"1\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def func_regalo(clave_func_dict): \n",
    "    if list_regalo[-1] == \"0\":\n",
    "        list_vendo.pop(-1)\n",
    "        list_vendo.append(\"0\")\n",
    "        list_regalo.pop(-1)\n",
    "        list_regalo.append(\"1\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def func_busco(clave_func_dict):  # if looking for, then is not a sell...\n",
    "    if list_busco[-1] == \"0\":\n",
    "        list_vendo.pop(-1)\n",
    "        list_vendo.append(\"0\")\n",
    "        list_busco.pop(-1)\n",
    "        list_busco.append(\"1\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def func_reparar(clave_func_dict):\n",
    "    if list_busco[-1] == \"0\":\n",
    "        list_reparar.pop(-1)\n",
    "        list_reparar.append(\"1\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def func_piezas(clave_func_dict):\n",
    "    if list_busco[-1] == \"0\":\n",
    "        list_piezas.pop(-1)\n",
    "        list_piezas.append(\"1\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def func_rebaja(clave_func_dict):\n",
    "    if list_rebaja[-1] == \"0\":\n",
    "        list_vendo.pop(-1)\n",
    "        list_vendo.append(\"0\")\n",
    "        list_rebaja.pop(-1)\n",
    "        list_rebaja.append(\"1\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def func_oferta(clave_func_dict):\n",
    "    if list_oferta[-1] == \"0\":\n",
    "        list_oferta.pop(-1)\n",
    "        list_oferta.append(\"1\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "func_dict = {                                                        # function dictionary\n",
    "    \"compro\":func_compro,\n",
    "    \"cambio\":func_cambio,\n",
    "    \"vendo\":func_vendo,\n",
    "    \"vende\":func_vendo,\n",
    "    \"regalo\":func_regalo,\n",
    "    \"busco\":func_busco,\n",
    "    \"busca\":func_busco,\n",
    "    \"reparar\":func_reparar,\n",
    "    \"piezas\":func_piezas,\n",
    "    \"rebajado\":func_rebaja,\n",
    "    \"rebaja\":func_rebaja,\n",
    "    \"oferta\":func_oferta\n",
    "}\n",
    "\n",
    "def remove_compro(clave_func_dict):\n",
    "    #list_compro.append(clave_func_dict\n",
    "    list_compro.remove(clave_func_dict)\n",
    "\n",
    "#rmv_func = {\"compro\":remove_compro}\n",
    "\n",
    "\n",
    "def urgente():                                                       # if some \"accion\" word is repeated on description, means urgency\n",
    "    list_urgente.remove('0')\n",
    "    list_urgente.append(\"1\")\n",
    "\n",
    "def eliminar_signos(txt):                                            # cleaning text\n",
    "    description = txt.replace(\":\",\" \")\n",
    "    descripcion = description.replace(\";\",\" \")\n",
    "    descripcion_1 = descripcion.replace(\"(\",\" \")\n",
    "    descripcion_2 = descripcion_1.replace(\")\",\" \")\n",
    "    descripcion_3 = descripcion_2.replace(\"/\",\" \")\n",
    "    descripcion_4 = descripcion_3.replace(\".\",\" \").lower()\n",
    "    descripcion_5 = descripcion_4.split()\n",
    "    return descripcion_5\n",
    "\n",
    "def default_atributes():                                            # default actions, means all is selling, if not then function will be called.\n",
    "    \"\"\"\n",
    "    Añade contenido a las diferentes listas con las que se trabaja en cada fila.\n",
    "    \"\"\"\n",
    "    list_cambio.append(\"0\")\n",
    "    list_compro.append(\"0\")\n",
    "    list_urgente.append(\"0\")\n",
    "    list_vendo.append(\"1\")\n",
    "    list_regalo.append(\"0\")\n",
    "    list_reparar.append(\"0\")\n",
    "    list_piezas.append(\"0\")\n",
    "    list_busco.append(\"0\")\n",
    "    list_brand.append(\"-\")\n",
    "\n",
    "### Inicio\n",
    "\n",
    "\n",
    "for pagina_anuncio in os.listdir('.'):                               # Se lee el contenido del directorio con un for en el current \".\" folder\n",
    "    with open(pagina_anuncio, 'r') as pagina_bruto:\n",
    "\n",
    "        pagina_analizar = pagina_bruto.read()                        # Se convierte en el objeto 'pagina_analizar' con el metodo read() de python\n",
    "        soup = BeautifulSoup(pagina_analizar, 'html.parser')         # Con Beautifulsoup se analiza la pagina_analizar con el 'html.parser' y se pasa una variable de nombre soup\n",
    "        node = soup.find('h1')                                       # se busca dentro de soup todo el contenido de la etiqueta h1 y ese contenido se mete en la variable node.\n",
    "\n",
    "    if  node is not None:                                            # avoiding skipping an error related to None. Mediante un if se comprueba que \"node\" no este vacio mediante la condicion \"if node is not None\"\n",
    "        descripcion = node.text                                      # mediante el metodo .text extraigo el texto que haya en node y lo paso a la variable descripción\n",
    "        descripcion = eliminar_signos(descripcion)                   # funcion que elimina signos puntuación ;,:,(,),/... y convierte en minusculas el texto\n",
    "        #print(descripcion)                              \n",
    "\n",
    "        default_atributes()                                          # Llamada a la función default_atributes().\n",
    "\n",
    "        for word_1 in descripcion:                                   # Descripcion es la variable donde se guarda el contenido del anuncio. Miro dentro de 'descripcion' con un for y compruebo si lo que voy leyendo está dentro de la lista accion.\n",
    "            if word_1 in accion:                                     # accion = [\"compro\",\"cambio\",\"vendo\",\"regalo\",\"busco\",\"busca\",'reparar','piezas']\n",
    "                func_dict[word_1](word_1)                            # Si la palabra está en la lista accion la introduzco dentro de un diccionario 'func_dict' con una función asociada e introduzco el parámetro de la función.\n",
    "                lista_palabras_para_eliminar.append(word_1)          # Añado esa acción a una lista de cadenas de texto llamada \"lista_palabras_para_eliminar\" que hace lo que su nombre claramente dice.\n",
    "\n",
    "            elif word_1 in compare:                                  # Si 'word_1' está dentro de la variable 'compare'. \n",
    "                                                                     # En la primera pasada 'compare' está vacia, esta variable me servirá para comparar el nombre del sintetizador\n",
    "                list_temp.append(word_1)                             # Se adjunta el contenido de 'word_1' a la lista 'list_temp'\n",
    "\n",
    "                for marca_sinte in list_temp:                        # El for recorre 'list_temp' \n",
    "                    marca_del_sinte += marca_sinte + ' '             # En el caso de que el nombre del sintetizador fuese de dos cadenas, aquí es donde se metería en una variable \n",
    "                    lista_palabras_para_eliminar.append(marca_sinte) # Despues se introduciría en \"lista_palabras_para_eliminar\"\n",
    "\n",
    "                #marca_del_sinte = ''\n",
    "                list_brand.pop(-1)\n",
    "                list_brand.append(marca_del_sinte)\n",
    "\n",
    "                compare = ''                                      # Si'compare' tuviera algun nombre, aquí se \"resetea\" el contenido. \n",
    "\n",
    "            elif word_1 in dict_marca:                               # si 'word_1' contiene el nombre de un sintetizador entonces:\n",
    "                size_brand = len(dict_marca[word_1])                 # obtenemos la longitud de la marca que extraemos del diccionario 'dict_marca'\n",
    "\n",
    "                if ((size_brand == 1) and (list_brand != \"-\")) :     # si la longitud de la marca es superior a 1 (es un caracter!) y no es \"-\"\n",
    "                    list_brand.pop(-1)                               # The pop() method removes the element at the specified position, en este caso la que sea la última posición.\n",
    "                    list_brand.append(word_1)                        # se inserta el contenido de la variable word_1 en la list_brand\n",
    "\n",
    "                elif ((size_brand == 1) and (list_brand == \"-\")) :   # si la longitud de la marca es igual a 1 y es el caracter '-'  \n",
    "                    list_descripcion.append(word_1)                  # entonces se introduce en 'list_descripcion' el caracter '-'\n",
    "\n",
    "                elif size_brand > 1:                                 # si la longitud es superior a 1 \n",
    "                    compare = dict_marca[word_1]                     # mete el contenido de 'dict_marca' en compare\n",
    "                    list_temp.append(word_1)                         # mete el contenido de word_1 en list_temp\n",
    "\n",
    "                elif list_brand != \"-\":                              \n",
    "                    list_descripcion.append(word_1)\n",
    "\n",
    "            marca_del_sinte = ''                                  # Si la variable 'marca_del_sinte' tuviera algun contenido, aquí se \"resetea\" ese contenido. \n",
    "        list_temp.clear()                                       # Si la lista 'list_temp' tuviera algun contenido, aquí se \"resetea\" ese contenido. \n",
    "        \n",
    "        \n",
    "        \n",
    "        # --- urgente\n",
    "        \n",
    "        duplicates = [element for element in lista_palabras_para_eliminar if lista_palabras_para_eliminar.count(element) > 1] # Detecta caracteres repetidos dentro de 'lista_de_palabras_para_eliminar' siempre que el tamaño de la lista sea superior a 1\n",
    "        unique_duplicates = list(set(duplicates))                                                                             # Muestra el elemento duplicado\n",
    "        size_unique_duplicates = len(duplicates)                                                                              # Muestra la longitud de esos dos elementos sumados 'size_unique_duplicates'\n",
    "        if size_unique_duplicates > 3:                                                                                        # Si la longitud 'size_unique_duplicates' es superior a 3 entonces llama a la función urgente.\n",
    "            urgente()                                                                                                         # Pinta un 1 en la columna urgente\n",
    "\n",
    "        for eliminar in lista_palabras_para_eliminar:\n",
    "            try:\n",
    "                descripcion.remove(eliminar)                # Conforme se identifican las acciones, y el nombre del sinte se van eliminando de la descripción del anuncio\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "        for palabras in descripcion:                       # Se recorre descripción despues de haber sido eliminado y lo que quede se introduce en una variable 'texto_descriptivo' \n",
    "            texto_descriptivo += palabras + ' '\n",
    "\n",
    "        texto_descriptivo_salida.append(texto_descriptivo) #  La varible con el contenido de 'texto_descriptivo' será el texto que finalmente quede como descripción en el csv final\n",
    "\n",
    "        texto_descriptivo =''                              # Sobre escribo el contenido de la variable 'texto_descriptivo' a modo de reseteo.\n",
    "\n",
    "\n",
    "        # --- price\n",
    "        \n",
    "        try:\n",
    "            # Intenta encontrar el elemento <div> con la clase 'ad-price' y extraer el texto\n",
    "            price = soup.find('div', class_='ad-price').text\n",
    "            # Quita el símbolo € del texto del precio\n",
    "            price = price.replace(\"€\", \"\")\n",
    "            \n",
    "        except AttributeError:\n",
    "            # Si el elemento no se encuentra, asigna \"N/A\" a la variable price\n",
    "            price = 0\n",
    "            # elimina el último elemento de list_price si existe (puede haber un error si la lista está vacía)\n",
    "        \n",
    "        finally:\n",
    "            # Agrega el valor de price (ya sea el precio encontrado o \"N/A\") a list_price\n",
    "            list_price.append(price)\n",
    "        \n",
    "\n",
    "        # --- user name\n",
    "\n",
    "        user = soup.find('div',class_='col-lg-7').a.text\n",
    "        list_user.append(user)\n",
    "        \n",
    "\n",
    "        # --- city\n",
    "\n",
    "        city = soup.find('div',class_='col-lg-7').div.strong.text\n",
    "        list_city.append(city)\n",
    "\n",
    "    \n",
    "        # --- published\n",
    "\n",
    "        publish = ' '\n",
    "\n",
    "        try:\n",
    "            # Encuentra el elemento div con la clase 'col-lg-7' y extrae el texto del div interno\n",
    "            published = soup.find('div', class_='col-lg-7').div.text.split()[-5:-2]\n",
    "\n",
    "            for indx in published:\n",
    "                list_original.append(indx)  # Agrega indx a la lista list_original\n",
    "\n",
    "                # Verifica si hay una barra diagonal en el elemento\n",
    "                if '/' in indx:\n",
    "                    # indx = indx.replace(\"/\", \"-\")  # Reemplaza \"/\" por \"-\"\n",
    "                    DD = indx[0:2]  # Extrae los primeros dos caracteres (día)\n",
    "                    MM = indx[3:5]  # Extrae los siguientes dos caracteres (mes)\n",
    "                    YYYY = indx[6:]  # Extrae los caracteres restantes (año)\n",
    "                    publish = f'{YYYY}/{MM}/{DD}'  # Crea la cadena de fecha en formato YYYY-MM-DD\n",
    "                    print(\"YYYY\", publish)\n",
    "                    \n",
    "\n",
    "                # Si \"hace\" está en el elemento, significa que ya no se extrae una fecha, sino la referencia a cuanto tiempo hace.\n",
    "                elif 'hace' in indx:\n",
    "                    #indx = indx.replace(\"/\", \"-\")  # Reemplaza \"/\" por \"-\"\n",
    "                    a = published.index(indx)  # Obtiene el índice del elemento actual\n",
    "\n",
    "                    # Combina el valor numérico y la unidad de tiempo (hace 2 horas, hace 5 días, hace 2 semanas...)\n",
    "                    publish = published[a + 1] + ' ' + published[a + 2] # <- con esto consigo obtener el formato de: hace 1 semana o hace 19 horas...\n",
    "                    #  el contenido de publish lo introduzco en el dataframe mas tarde modificaré ese formato tan molesto \n",
    "                    print(\"publish\", publish)\n",
    "                    \n",
    "\n",
    "        except (AttributeError, IndexError):\n",
    "            # Si ocurren excepciones debido a problemas de atributos o índices, asigna \"N/A\" a la variable publish\n",
    "            publish = \" \"\n",
    "\n",
    "        finally:\n",
    "            # Agrega el valor final de \"publish\" a la lista list_published\n",
    "            list_published.append(publish)\n",
    "\n",
    "    \n",
    "        \n",
    "        # --- expire \n",
    "\n",
    "        expire = soup.find('div',class_=\"expira\").text.split()[1]\n",
    "        #expire = expire.replace(\"/\",\"-\")\n",
    "        DD = expire[0:2]\n",
    "        MM = expire[3:5]\n",
    "        YYYY = expire[6:]\n",
    "        date_corrected = f'{YYYY}-{MM}-{DD}'\n",
    "        list_expire.append(date_corrected)\n",
    "        \n",
    "        \n",
    "\n",
    "        # --- times seen\n",
    "        \n",
    "        seen = soup.find('div',class_=\"expira\").text.split()[4]\n",
    "        list_times_seen.append(seen)\n",
    "\n",
    "        lista_palabras_para_eliminar.clear()\n",
    "        #print(pagina_anuncio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c06356-a30b-4b40-86ce-90d4e5e8c772",
   "metadata": {},
   "source": [
    "### About BeautifulSoup Warning:\n",
    "\n",
    "This bug report is a duplicate of:  Bug #1873787: Suppress UserWarning * looks like a URL. Edit Remove\n",
    "\n",
    "https://bugs.launchpad.net/beautifulsoup/+bug/1955450\n",
    "\n",
    "    ...Beautiful Soup generally takes the approach of trying to give \"helpful\" error/warning codes so that a user understands why things are not working the way they expect. While every developer may have a different opinion on how helpful error/warnings should be done, Beautiful Soup has taken a more ambitious approach..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c71c6",
   "metadata": {},
   "source": [
    "## 3.8 Date extraction\n",
    "\n",
    "The next step is to know what is the extraction date. This is an important fact since because it will serve as a reference to know how long means 3 days, 1 week, 5 hours since the records were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9310eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hoy = dt.datetime.now()\n",
    "year=str(hoy.year)\n",
    "\n",
    "month=str(hoy.month)\n",
    "day=str(hoy.day)\n",
    "\n",
    "date_scrapped = year + '/' + month + '/' + day\n",
    "\n",
    "# ex: date_scrapped = '26' + '/' + '08' + '/' + '2022' \n",
    "\n",
    "date_scrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35460d7",
   "metadata": {},
   "source": [
    "- Dataframe created in `df` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12bc24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'urgent':list_urgente,\n",
    "                   'buy':list_compro,\n",
    "                   'change':list_cambio,\n",
    "                   'sell':list_vendo,\n",
    "                   'price':list_price,\n",
    "                   'gift':list_regalo,\n",
    "                   'search':list_busco,\n",
    "                   'repair':list_reparar,\n",
    "                   'parts':list_piezas,\n",
    "                   'synt_brand':list_brand,\n",
    "                   'description':texto_descriptivo_salida,\n",
    "                   'city':list_city,\n",
    "                   'published':list_published,\n",
    "                   'expire':list_expire,\n",
    "                   'date_scrapped':date_scrapped,\n",
    "                   'seen':list_times_seen\n",
    "                  },index = list(range(1,len(texto_descriptivo_salida)+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b4cd01",
   "metadata": {},
   "source": [
    "## 3.9 Clean the column of the publication dates.\n",
    "\n",
    "\n",
    "As we can see sometimes the format is correct and sometimes indicates moments related to the date we are on. so it has to be corrected.\n",
    "\n",
    "The solution is to create a function that reads that format and converts it to the correct date and format.\n",
    "\n",
    "\n",
    "For this we have to implement all the cases that can be given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b629d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "semanas = ['1 semana', '2 semanas', '3 semanas', '4 semanas']\n",
    "dias = ['1 día', '2 días', '3 días', '4 días', '5 días', '6 días', '7 días']\n",
    "horas = ['1 hora','2 horas', '3 horas', '4 horas', '5 horas', '6 horas',\n",
    "        '7 horas','8 horas', '9 horas', '10 horas', '11 horas', '12 horas',\n",
    "        '13 horas', '14 horas','15 horas', '16 horas', '17 horas', '18 horas',\n",
    "        '19 horas', '20 horas', '21 horas', '22 horas','23 horas', '24 horas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2198c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes=[]\n",
    "for mint in range(1,61):\n",
    "    if mint < 2:\n",
    "        texto = str(mint) + ' minuto'\n",
    "        minutes.append(texto)\n",
    "    else:\n",
    "        texto = str(mint) + ' minutos'\n",
    "        minutes.append(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1226207",
   "metadata": {},
   "source": [
    "- `nice_format` is the function that is responsible for identifying the time intervals that the web gives us and making a time conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_format(parameter):\n",
    "\n",
    "    days_inweek = 7\n",
    "    hoy = dt.datetime.now()\n",
    "    year=str(hoy.year)\n",
    "    month=str(hoy.month)\n",
    "    day=str(hoy.day)\n",
    "\n",
    "    date_scrapped = year + '/' + month + '/' + day\n",
    "    \n",
    "    current_datetime = dt.datetime.strptime(date_scrapped,\"%Y/%m/%d\")  \n",
    "    \n",
    "    \n",
    "    if parameter in semanas:\n",
    "    \n",
    "        num_semana = parameter.split()\n",
    "        num_semana = int(num_semana[0])\n",
    "        cambio_semana = semanas[num_semana-1]\n",
    "        \n",
    "        dias_semana = (num_semana * days_inweek)\n",
    "        \n",
    "        fecha_real_semana = current_datetime - dt.timedelta(dias_semana)\n",
    "        \n",
    "        fecha_real_semana = fecha_real_semana.strftime(\"%Y/%m/%d\")\n",
    "                \n",
    "        df['published'] = df['published'].replace( to_replace = cambio_semana, value = fecha_real_semana) #+ ' semana'\n",
    "        \n",
    "        \n",
    "    if parameter in dias:\n",
    "        num_dia = parameter.split()\n",
    "        num_dias = int(num_dia[0])\n",
    "        cambio_dia = dias[num_dias-1]\n",
    "\n",
    "        fecha_real_dia = current_datetime - dt.timedelta(num_dias)\n",
    "        fecha_real_dia = fecha_real_dia.strftime(\"%Y/%m/%d\")\n",
    "        \n",
    "        df['published'] = df['published'].replace( to_replace = cambio_dia, value = fecha_real_dia) #+ ' semana'\n",
    "        \n",
    "        \n",
    "    if parameter in horas:\n",
    "        num_hora = parameter.split()\n",
    "        num_hora = int(num_hora[0])\n",
    "        \n",
    "        if (parameter != '24 horas'):\n",
    "            hora_real = current_datetime\n",
    "            hora_real = hora_real.strftime(\"%Y/%m/%d\")\n",
    "            \n",
    "            df['published'] = df['published'].replace(to_replace = parameter,\n",
    "                                              value = hora_real)\n",
    "        \n",
    "        elif parameter == '24 horas':\n",
    "            horas_24 = 1\n",
    "            hora_real = current_datetime - dt.timedelta(horas_24)\n",
    "            hora_real = hora_real.strftime(\"%Y/%m/%d\")\n",
    "            \n",
    "            df['published'] = df['published'].replace( to_replace = parameter,value = hora_real ) #+ ' semana'\n",
    "    \n",
    "    \n",
    "    if parameter in minutes:\n",
    "        horas_24 = 1\n",
    "        hora_real = current_datetime - dt.timedelta(horas_24)\n",
    "        hora_real = hora_real.strftime(\"%Y/%m/%d\")\n",
    "            \n",
    "        df['published'] = df['published'].replace( to_replace = parameter,value = hora_real ) #+ ' semana'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d09841",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['published'].apply(nice_format) # Make changes on Series\n",
    "print('')                          # Avoiding verbosing print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea4b72-4330-4954-b916-7b8c15301c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['published'] = df['published'].str.replace('-', '/')\n",
    "df['expire'] = df['expire'].str.replace('-', '/')\n",
    "df['date_scrapped'] = df['date_scrapped'].str.replace('-', '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560de244",
   "metadata": {},
   "source": [
    "### 4. Anonimizing user names\n",
    "\n",
    "Although users in the forum use aliases, the most sensible thing is to create a function that anonymizes the name of the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonimizer(value):\n",
    "    variable = 0\n",
    "    for letras in value:\n",
    "        variable += int(ord(letras))\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd121700",
   "metadata": {},
   "source": [
    "### Last step\n",
    "\n",
    "We already have all the data inside the dataframe now the only thing left to do is to save the content in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a8ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_hispa_15_08_2023_fix.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92a775-d972-4fa6-bc67-c6abe0b44e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b08ca7490639a610c09048f473d1b1514aaa85648d7e388c5f947d92672b22b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
