My name is [Alberto Jimenez](https://www.linkedin.com/in/alberto-jimenez-8a8559222/), I studied electronics to understand the workings of electronic musical instruments and the inner of sound design. 

I was working in different electronics and audiovisual companies as a technician, and also as a freelance sound designer for a company online called [Gameprefabs today **Unity Asset Store**](https://assetstore.unity.com/publishers/2954), and as an [electronic music composer profile](https://www.imdb.com/title/tt0466106/?ref_=fn_al_tt_1) for a couple of movies while I discover Linux, [Arduino](https://www.arduino.cc/), and the Open software community.

Finally, [I built my synth](https://midimachines.wordpress.com/), the synthesizer which I went into electronics! and somehow it close the cycle of electronics and technician stuff, then I needed to update myself, and improve professionally, so I did it by studying for a [Master's degree in Business Intelligence and Big Data](https://accounts.iebschool.com/mi-diploma/abaa0886b52591b851a33c17b4653f20/) online. 

I decided to extract the maximum benefit from the time I was studying for my master's so *with a fair knowledge of programming Python*, but with a **very great need to have the content of the videos transcribed**, I had to create a very simple tool to be able to make the transcriptions of the Vimeo videos and have all the text in the video lessons, i called: [Sonus transcriber](https://github.com/albertjimrod/personal_projects/blob/main/Sonus_transcribere/sonus%20transcriber.md)

Suddenly a new world of possibilities opened up in front of me, so I decided to apply my new knowledge in a field that was already known to me and, I did it in [R language](https://www.r-project.org/) in my master's thesis.

These are some of the projects I have been working on:

# Data science projects
|||
|:---|:---|
|**R**||
||[FREQUENCY CLASSIFICATION OF SOUND SAMPLES THROUGH THE REDUCTION OF DIMENSIONALITY](https://github.com/albertjimrod/personal_projects/tree/main/Master_thesis)|
|**Python**||
|           |[00-Profitable App Profiles for the App Store and Google Play Markets](https://github.com/albertjimrod/Data-science-projects/tree/main/01%20Python/00-Profitable%20App%20Profiles%20for%20the%20App%20Store%20and%20Google%20Play%20Markets)|
|           |[01-Hacker News Post](https://github.com/albertjimrod/Data-science-projects/tree/main/01%20Python/01-Exploring%20Hacker%20News%20Posts)|
|**Data Analisis Visualization**||
|           |[Traffic on the I-94 Interstate highway.](https://github.com/albertjimrod/Data-science-projects/blob/37af6342916b17e4c1d6b126217a877c1e5b3edc/02%20Data_Analisis_Visualization/01_Data%20Visualization%20Fundamentals/Traffic%20on%20the%20I-94%20Interstate%20highway.ipynb)|
|           |[Exploring eBay Car Sales Data](https://github.com/albertjimrod/Data-science-projects/blob/ebefd2a45838ddcb26138b663837186319b67883/02%20Data_Analisis_Visualization/00_Numpy%20introduction/Exploring%20Ebay%20Car%20Sales%20Data%20v2.ipynb)|
|           |Storytelling Data Visualization and Information Design|
|**Data_Cleaning**||
||Visualizing Earnings Based On College Majors(Extra)|
||[Clean and Analyze Employee Exit Surveys](https://github.com/albertjimrod/Data-science-projects/blob/main/03_Data_Cleaning/Clean%20and%20Analyze%20Employee%20Exit%20Surveys/README.md)|
|**SQL**||
||[Analyzing CIA Factbook Data Using SQL](https://github.com/albertjimrod/Data-science-projects/blob/main/05_SQL/Analyzing%20CIA%20Factbook%20Data%20Using%20SQL/README.md)|
|**Web Scrapping**||
||W||



# [Personal_projects](https://github.com/albertjimrod/personal_projects)

These are some of the personal projects I have been doing:

- [Sonus transcribere](https://github.com/albertjimrod/personal_projects/tree/main/Sonus_transcribere)

	This is the first project on this list is , it is a very simple audio transcriber where I use the google API for the first time. While I was studying [](https://accounts.iebschool.com/mi-diploma/abaa0886b52591b851a33c17b4653f20/) I realized that I wasted too much time taking annotations of the videos and that they did not have the possibility to transcribe the text since they were hosted on Vimeo privately. Therefore I had to invent the way to obtain the content of the lessons in a written support and then proceed to the study of the document.

- [FREQUENCY CLASSIFICATION OF SOUND SAMPLES THROUGH THE REDUCTION OF DIMENSIONALITY THROUGH MULTIDIMENSIONAL SCALING](https://github.com/albertjimrod/personal_projects/tree/main/Master_thesis)

	I am not an expert in business analysis and my background is practically based on sound therefore it seemed to me that I should be honest in the realization of the project and apply my experience in the field of sound. I thought it will be appropriate to apply techniques that are used in marketing to group potential customers in the world of sound and thus avoid dependence on data sets, and that's how I carried out this project.



- [Bootstrap Dashboard Interface Design](https://github.com/albertjimrod/personal_projects/tree/main/Bootstrap%20Dashboard%20Interface%20Design)

	A fairly recurring question that arises was: how could I make a web page that had an integrated machine learning model and that allows the visualization of data?
	
	As the answer did not go through a simple WordPress I start to understand how serious websites were done, and I found Django. 
	
	So I started working on what would be the design of the interface for a page that worked with Django and thus understand the ins and outs of this interesting Framework.
	
	
- [Web_scrapping](https://github.com/albertjimrod/personal_projects/tree/main/web_scrapping)
	
	Obtaining the necessary data automatically for later use and regardless of the datasets that circulate on the Internet, is one of the tools that a data analyst must have in their own toolbox (or at least that's what I think).

	## Proyects chronology: 

	- [Hispasonic](https://www.hispasonic.com/anuncios/teclados-sintetizadores)

	- [Xuxes](https://www.xuxes.store/) 

	- [Eurogrow](https://eurogrow.es/)

	## Things I've learned:

	The issue I have experienced have been several:

	### Hispasonic:

	 - This was the first project, and as such I only made use of the function libraries: Requests and BeautifulSoup the most important challenge was to obtain the dates related to the day on which I did the scrapping because if the user had modified the date it appeared referenced as 2 weeks ago, 5 days ago, 5 minutes ago...

	So it was a challenge to adjust that time scale to the date that corresponded to it.

	![[sample_hispasonic_output.png](sample_hispasonic_output.png)](https://github.com/albertjimrod/personal_projects/blob/eda3a5e2834ca3e162749296f8a43d7552692aff/web_scrapping/sample_hispasonic_output.png)


	### Xuxes:

	After having finished the previous project facing this one was not so difficult since it did not require dates, however I began to realize that I needed another way to enter the data.

	One of the things I had to fine-tune because I didn't know enough was to work with regular expressions which saved me most of the time.

	![[xuxes_csv.png](/web_scrapping/eurogrow_cvs.png)](https://github.com/albertjimrod/personal_projects/blob/eda3a5e2834ca3e162749296f8a43d7552692aff/web_scrapping/sample_hispasonic_output.png)

	### Eurogrow:

	Seeing that the xuxes website was not too complex and suspecting that something I didn't quite understand in depth, I decided to continue with the world of CBD (as there are many pages with these products) and get data on eurogrow.es. Immediately the following points appeared:

	- The need to get out of the comfort of using Jupyter notebook and learn how to use a new IDE. In this case Visual Studio Code.
	- Understanding that there is a systematized process in the extraction of data, through the use of function libraries such as:
	 - Requests https://requests.readthedocs.io/en/latest/ the connection with the web to be studied.
	 - BeautifulSoup: https://beautiful-soup-4.readthedocs.io/en/latest/ allows the extraction of data from documents of type HTML and XML.
	 - Selenium (webdriver): https://www.selenium.dev/documentation/webdriver/ Controls a browser natively, as a user would, either locally or on a remote machine using the Selenium server, marks a leap forward in terms of browser automation.

![eurogrow_cvs](https://github.com/albertjimrod/personal_projects/blob/eda3a5e2834ca3e162749296f8a43d7552692aff/web_scrapping/eurogrow_cvs.png)

Learn that there are pages which there are different technologies and that depending on how these pages are made we must access the data through a different strategy.

For example, a common technique when extracting information is to download those pages that contain what we need to avoid overloading the server pages, however in pages where AJAX is used that is where the sending and return of data by the server is done asynchronously, this is not possible since  when opening the page in the browser it tries to connect to the server automatically making the use of this way of proceeding completely unfeasible.

Also in these projects have made me understand that it is as important to know what is the technology behind each of the pages, as to know what is the structure or importance of the library functions since all this will condition how I will have to make use of some techniques or others.

There are still many things to learn but the main objective at the moment is fulfilled, which was to obtain the data of different pages.
